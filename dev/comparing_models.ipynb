{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e41003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import deepirtools\n",
    "from deepirtools import IWAVE\n",
    "from factor_analyzer import Rotator\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "plt.rcParams['figure.figsize'] = (15, 12)\n",
    "deepirtools.manual_seed(123) # Seed for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3ae4d6",
   "metadata": {},
   "source": [
    "# Comparing by gender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d024115e",
   "metadata": {},
   "source": [
    "## Men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe812c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = 1           # age class 'AK'\n",
    "test_size = 0.2     # train-test split\n",
    "sub = False         # subjective meassures\n",
    "save_dir = './paper_models_test'\n",
    "\n",
    "dat = pd.read_csv('../data/merged_male.csv')\n",
    "\n",
    "y_0 = dat['LZ']\n",
    "dat = dat.drop(['TalentID', 'AK', 'LZ'], axis=1).reset_index(drop=True)\n",
    "X_0 = dat.iloc[:,:]\n",
    "\n",
    "# # english variable-names\n",
    "X_names = ['relative age', 'height', 'weight', 'sprint (20m)', 'agility','dribbling','ball control','juggling','tactical skills','kicking skills','endurance','psychological skills']\n",
    "# X_0 = dat.iloc[:, 2:c]\n",
    "# y_0 = dat.iloc[:, 16]\n",
    "X_0.columns = X_names\n",
    "\n",
    "\n",
    "#X, X_test, y, y_test = train_test_split(X_0, y_0, test_size=test_size, random_state=42, stratify=y_0)\n",
    "#X.columns = X_names\n",
    "\n",
    "\n",
    "# ___ SCALING\n",
    "# MinMax [0,1]\n",
    "#scaler_train = StandardScaler().fit(X)\n",
    "#df_train = scaler_train.transform(X)\n",
    "#y_train = np.asarray(y)\n",
    "#df_test = scaler_train.transform(X_test)\n",
    "\n",
    "# torch\n",
    "#dft = torch.tensor(df_train)\n",
    "#dftest = torch.tensor(df_test)\n",
    "#sample_size = df_train.shape[0]\n",
    "#test_size = df_test.shape[0]\n",
    "#Y = dft.view(sample_size, -1)\n",
    "#Ytest = dftest.view(test_size, -1)\n",
    "\n",
    "# Full data\n",
    "X_full = X_0.copy()\n",
    "y_full = y_0.copy()\n",
    "\n",
    "scaler = StandardScaler().fit(X_full)\n",
    "df = scaler.transform(X_full)\n",
    "y = np.asarray(y_full)\n",
    "\n",
    "dft = torch.tensor(df)\n",
    "sample_size = df.shape[0]\n",
    "Y = dft.view(sample_size, -1)\n",
    "n_items = Y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36134d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 4\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#ref_idxs = Y.var(dim = 0).sort(descending = True)[1][:latent_size] # Find anchor items.\n",
    "ref_idxs = [1,3,6,8]\n",
    "A = torch.ones(latent_size * n_items)\n",
    "b = torch.zeros(latent_size * n_items)\n",
    "for factor_idx in range(latent_size):\n",
    "    ref_idx = ref_idxs[factor_idx]\n",
    "    A[n_items * factor_idx + ref_idx] = 0\n",
    "    b[n_items * factor_idx + ref_idx] = 1 # Fix anchor item's loading on one factor to one.\n",
    "A = A.diag()\n",
    "ints_mask = torch.zeros(n_items)\n",
    "\n",
    "model_name = 'iwave_male'\n",
    "inf_net = [15,8]\n",
    "\n",
    "# model\n",
    "iwave = IWAVE(model_type = \"normal\",\n",
    "              learning_rate = 5e-4 if device==\"cpu\" else 1e-3,\n",
    "              gradient_estimator='dreg',\n",
    "              n_intervals = 100,\n",
    "              device = device,\n",
    "              A = A,\n",
    "              b = b,\n",
    "              ints_mask = ints_mask,\n",
    "              inference_net_sizes = inf_net,\n",
    "              latent_size = latent_size,\n",
    "              n_items = n_items,\n",
    "              fixed_variances = False,\n",
    "              fixed_means = False,\n",
    "              use_spline_prior = False,\n",
    "              log_interval = 25,\n",
    "              )\n",
    "\n",
    "iwave.load_model(model_name, \"./saved_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c4bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nIWAVE\n",
    "model_name = 'niwave_u13'\n",
    "load_model = os.path.exists(save_dir + '/' + model_name + '.pth')\n",
    "\n",
    "# specs\n",
    "latent_size = 4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ref_idxs = [1,3,6,8]\n",
    "A = torch.ones(latent_size * n_items)\n",
    "b = torch.zeros(latent_size * n_items)\n",
    "for factor_idx in range(latent_size):\n",
    "    ref_idx = ref_idxs[factor_idx]\n",
    "    A[n_items * factor_idx + ref_idx] = 0\n",
    "    b[n_items * factor_idx + ref_idx] = 1 # Fix anchor item's loading on one factor to one.\n",
    "A = A.diag()\n",
    "ints_mask = torch.zeros(n_items)\n",
    "inf_net = [15,8]\n",
    "\n",
    "#### Load second model\n",
    "model_name = 'niwave_male'\n",
    "inf_net = [15,8]\n",
    "\n",
    "niwave = IWAVE(model_type = \"normal\",\n",
    "              learning_rate = 5e-4 if device==\"cpu\" else 1e-3, # Bigger learning rate with increased\n",
    "              gradient_estimator='dreg',\n",
    "              n_intervals = 100,\n",
    "              device = device,\n",
    "              A = A,\n",
    "              b = b,\n",
    "              ints_mask = ints_mask,\n",
    "              inference_net_sizes = inf_net,\n",
    "              latent_size = latent_size,\n",
    "              n_items = n_items,\n",
    "              fixed_variances = False,\n",
    "              fixed_means = False,\n",
    "              use_spline_prior = True,\n",
    "              count_bins = 32,\n",
    "              flow_length = 2,\n",
    "              log_interval = 25,\n",
    "              )\n",
    "\n",
    "niwave.load_model(model_name, \"./saved_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2858ce03",
   "metadata": {},
   "source": [
    "#### Log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b13fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xt_test = torch.tensor(df_test)\n",
    "#test_size = Xt_test.shape[0]\n",
    "#Y_test = Xt_test.view(test_size, -1)\n",
    "\n",
    "ll = iwave.log_likelihood(data = Y, iw_samples = 5000)\n",
    "nll = niwave.log_likelihood(data = Y, iw_samples = 5000) # Increasing iw_samples\n",
    "print(-ll/sample_size,-nll/sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1597338b",
   "metadata": {},
   "source": [
    "#### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba184bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_iwave = iwave.scores(Y, mc_samples=50, iw_samples=50)\n",
    "scores_iwave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a313bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_niwave = niwave.scores(Y, mc_samples=50, iw_samples=50)\n",
    "scores_niwave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea7ddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why this order of index?\n",
    "final = pd.DataFrame(dat)\n",
    "final['dim1_iwave'] = scores_iwave[:,3]\n",
    "final['dim2_iwave'] = scores_iwave[:,0]\n",
    "final['dim3_iwave'] = scores_iwave[:,2]\n",
    "final['dim4_iwave'] = scores_iwave[:,1]\n",
    "final['dim1_niwave'] = scores_niwave[:,3]\n",
    "final['dim2_niwave'] = scores_niwave[:,0]\n",
    "final['dim3_niwave'] = scores_niwave[:,1]\n",
    "final['dim4_niwave'] = scores_niwave[:,2]\n",
    "final['y'] = y\n",
    "\n",
    "scaled_names = ['relative age scaled',\n",
    "                'height scaled',\n",
    "                'weight scaled',\n",
    "                'sprint (20m) scaled',\n",
    "                'agility scaled',\n",
    "                'dribbling scaled',\n",
    "                'ball control scaled',\n",
    "                'juggling scaled',\n",
    "                'tactical skills scaled',\n",
    "                'kicking skills scaled',\n",
    "                'endurance scaled',\n",
    "                'psychological skills scaled']\n",
    "\n",
    "final = pd.concat([final,pd.DataFrame(df, columns=scaled_names)],axis=1)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eab284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(save_dir+'/data_scores', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cc168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "succ = final[final['y']==1]\n",
    "fail = final[final['y']==0]\n",
    "succ_scores = succ.iloc[:,11:15]\n",
    "fail_scores = fail.iloc[:,11:15]\n",
    "\n",
    "succ_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66159e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "test_result = np.transpose(succ.iloc[:, 1:2].describe().iloc[[1,2], :])\n",
    "temp_0 = np.transpose(fail.iloc[:, 1:2].describe().iloc[[1,2], :])\n",
    "stat, p = ttest_ind(succ.iloc[:, 1],fail.iloc[:, 1])\n",
    "test_result[['mean_0', 'std_0']] = temp_0\n",
    "test_result[\"t-statistic\"] = stat\n",
    "test_result[\"p-value\"] = p\n",
    "for i in range(2, final.iloc[:, 1::].shape[1]):\n",
    "    stat, p = ttest_ind(succ[final.columns[i]],fail[final.columns[i]])\n",
    "    temp = np.transpose(succ.iloc[:, i:(i+1)].describe().iloc[[1,2], :])\n",
    "    temp_0 = np.transpose(fail.iloc[:, i:(i+1)].describe().iloc[[1,2], :])\n",
    "    temp[['mean_0', 'std_0']] = temp_0\n",
    "    temp[\"t-statistic\"] = stat\n",
    "    temp[\"p-value\"] = p\n",
    "    test_result = pd.concat([test_result,temp],axis=0)\n",
    "    # test_result = test_result.append(temp)\n",
    "    # print('For ', name, 'the test statistic is %.3f and p=%.3f' % (stat, p))\n",
    "test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e489338b",
   "metadata": {},
   "source": [
    "### PCA Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620a7097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "#pca_scree = PCA(n_components = 0.75, svd_solver='full')\n",
    "pca_scree = PCA(svd_solver='full')\n",
    "pca_scree.fit(df)\n",
    "reduced = pca_scree.transform(df)\n",
    "pca_scree.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ce6f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.plot(pca_scree.explained_variance_ratio_, marker='o')\n",
    "plt.xlabel(\"Eigenvalue number\")\n",
    "plt.ylabel(\"Eigenvalue size\")\n",
    "plt.title(\"Scree Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d60d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 4, svd_solver='full',)\n",
    "pca.fit(df)\n",
    "reduced = pca.transform(df)\n",
    "loadings = pd.DataFrame(pca.components_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b605ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(25,12))\n",
    "sns.heatmap(ax=axs[0], data=loadings, annot=True, linewidths=0.5, vmin=loadings.min().min(), vmax=loadings.max().max(), center=0,xticklabels=[\"Factor 1\", \"Factor 2\",\"Factor 3\",\"Factor 4\"], yticklabels=X_names).set(title='PCA loadings')\n",
    "sns.heatmap(ax=axs[1], data=rot_loadings_iwave[:,[3,0,2,1]], annot=True, linewidths=0.5, vmin=rot_loadings_iwave.min(), vmax=rot_loadings_iwave.max(), center=0, xticklabels=[\"Factor 1\", \"Factor 2\",\"Factor 3\",\"Factor 4\"], yticklabels=X_names).set(title='Loadings oblique')\n",
    "sns.heatmap(ax=axs[2], data=rot_loadings_niwave[:,[3,0,1,2,]], annot=True, linewidths=0.5, vmin=rot_loadings_niwave.min(), vmax=rot_loadings_niwave.max(), center=0, xticklabels=[\"Factor 1\", \"Factor 2\",\"Factor 3\",\"Factor 4\"], yticklabels=X_names).set(title='Loadings oblique_spl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4531628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(16,7), frameon=True)\n",
    "sns.heatmap(ax=axs[0], data=abs(loadings), annot=False, linewidths=0.5, linecolor='black', vmin=0, center=loadings.max().max()/2, vmax=loadings.max().max(),xticklabels=[\"Factor 1\", \"Factor 2\",\"Factor 3\",\"Factor 4\"], yticklabels=X_names, cmap = plt.cm.Greys, cbar=True, cbar_kws={'format': matplotlib.ticker.FixedFormatter(['0','max']),\"ticks\":[0,loadings.max().max()],}).set(title='PCA')\n",
    "sns.heatmap(ax=axs[1], data=abs(rot_loadings_iwave[:,[3,0,2,1]]), annot=False, linewidths=0.5, linecolor='black', vmin=0, center=rot_loadings_iwave.max()/2, vmax=rot_loadings_iwave.max(), xticklabels=[\"Factor 1\", \"Factor 2\",\"Factor 3\",\"Factor 4\"], yticklabels=False, cmap = plt.cm.Greys, cbar=True, cbar_kws={'format': matplotlib.ticker.FixedFormatter(['0','max']),\"ticks\":[0,rot_loadings_iwave.max()],}).set(title='Linear loadings')\n",
    "sns.heatmap(ax=axs[2], data=abs(rot_loadings_niwave[:,[3,0,1,2,]]), annot=False, linewidths=0.5, linecolor='black', vmin=0, center=(rot_loadings_niwave.max()-0.7)/2,vmax=rot_loadings_niwave.max()-0.7, xticklabels=[\"Factor 1\", \"Factor 2\",\"Factor 3\",\"Factor 4\"], yticklabels=False, cmap = plt.cm.Greys, cbar_kws={'format': matplotlib.ticker.FixedFormatter(['0','max']),\"ticks\":[0,rot_loadings_niwave.max()-0.7],}).set(title='Nonlinear loadings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03402f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_load_table = torch.clone(rot_loadings_iwave)\n",
    "rot_load_table_spl = torch.clone(rot_loadings_niwave)\n",
    "\n",
    "loadings_table = loadings.copy()\n",
    "loadings_table['variable'] = X_names\n",
    "loadings_table.set_index('variable', inplace=True)\n",
    "loadings_table.columns = ['fact. 1', 'fact. 2', 'fact. 3', 'fact. 4']\n",
    "\n",
    "loadings_table[['iwave fact. 1', 'iwave fact. 2', 'iwave fact. 3', 'iwave fact. 4']] = rot_loadings_iwave[:,[3,0,2,1]]\n",
    "loadings_table[['niwave fact. 1', 'niwave fact. 2', 'niwave fact. 3', 'niwave fact. 4']] = rot_loadings_niwave[:,[3,0,1,2,]]\n",
    "\n",
    "loadings_table = round(loadings_table,2)\n",
    "cut_percent = 0.1\n",
    "pca_cut = cut_percent*loadings.max().max()\n",
    "iwave_cut = np.asarray(cut_percent*rot_loadings_iwave.max())\n",
    "niwave_cut = np.asarray(cut_percent*(rot_loadings_niwave.max()-0.7))\n",
    "# pca\n",
    "loadings_table.loc[np.abs(loadings_table['fact. 1']) < pca_cut, 'fact. 1'] = '.'\n",
    "loadings_table.loc[np.abs(loadings_table['fact. 2']) < pca_cut, 'fact. 2'] = '.'\n",
    "loadings_table.loc[np.abs(loadings_table['fact. 3']) < pca_cut, 'fact. 3'] = '.'\n",
    "loadings_table.loc[np.abs(loadings_table['fact. 4']) < pca_cut, 'fact. 4'] = '.'\n",
    "# iwave\n",
    "loadings_table.loc[np.abs(loadings_table['iwave fact. 1']) < iwave_cut, 'iwave fact. 1'] = '.'\n",
    "loadings_table.loc[np.abs(loadings_table['iwave fact. 2']) < iwave_cut, 'iwave fact. 2'] = '.'\n",
    "loadings_table.loc[np.abs(loadings_table['iwave fact. 3']) < iwave_cut, 'iwave fact. 3'] = '.'\n",
    "loadings_table.loc[np.abs(loadings_table['iwave fact. 4']) < iwave_cut, 'iwave fact. 4'] = '.'\n",
    "# niwave\n",
    "loadings_table.loc[np.abs(loadings_table['niwave fact. 1']) < niwave_cut, 'niwave fact. 1'] = '.'\n",
    "loadings_table.loc[np.abs(loadings_table['niwave fact. 2']) < niwave_cut, 'niwave fact. 2'] = '.'\n",
    "loadings_table.loc[np.abs(loadings_table['niwave fact. 3']) < niwave_cut, 'niwave fact. 3'] = '.'\n",
    "loadings_table.loc[np.abs(loadings_table['niwave fact. 4']) < niwave_cut, 'niwave fact. 4'] = '.'\n",
    "\n",
    "\n",
    "print(round(loadings_table,2).to_latex(escape=True, index=True, index_names=False, column_format='lrrrrrrrrrrrr', ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2aa70f",
   "metadata": {},
   "source": [
    "## Women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52cda83",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = 1           # age class 'AK'\n",
    "test_size = 0.2     # train-test split\n",
    "sub = False         # subjective meassures\n",
    "save_dir = './paper_models_test'\n",
    "\n",
    "dat = pd.read_csv('../data/merged_female.csv')\n",
    "\n",
    "y_0 = dat['LZ']\n",
    "dat = dat.drop(['TalentID', 'AK', 'LZ'], axis=1).reset_index(drop=True)\n",
    "X_0 = dat.iloc[:,:]\n",
    "\n",
    "# # english variable-names\n",
    "X_names = ['relative age', 'height', 'weight', 'sprint (20m)', 'agility','dribbling','ball control','juggling','tactical skills','kicking skills','endurance','psychological skills']\n",
    "# X_0 = dat.iloc[:, 2:c]\n",
    "# y_0 = dat.iloc[:, 16]\n",
    "X_0.columns = X_names\n",
    "\n",
    "\n",
    "#X, X_test, y, y_test = train_test_split(X_0, y_0, test_size=test_size, random_state=42, stratify=y_0)\n",
    "#X.columns = X_names\n",
    "\n",
    "\n",
    "# ___ SCALING\n",
    "# MinMax [0,1]\n",
    "#scaler_train = StandardScaler().fit(X)\n",
    "#df_train = scaler_train.transform(X)\n",
    "#y_train = np.asarray(y)\n",
    "#df_test = scaler_train.transform(X_test)\n",
    "\n",
    "# torch\n",
    "#dft = torch.tensor(df_train)\n",
    "#dftest = torch.tensor(df_test)\n",
    "#sample_size = df_train.shape[0]\n",
    "#test_size = df_test.shape[0]\n",
    "#Y = dft.view(sample_size, -1)\n",
    "#Ytest = dftest.view(test_size, -1)\n",
    "\n",
    "# Full data\n",
    "X_full = X_0.copy()\n",
    "y_full = y_0.copy()\n",
    "\n",
    "scaler = StandardScaler().fit(X_full)\n",
    "df = scaler.transform(X_full)\n",
    "y = np.asarray(y_full)\n",
    "\n",
    "dft = torch.tensor(df)\n",
    "sample_size = df.shape[0]\n",
    "Y = dft.view(sample_size, -1)\n",
    "n_items = Y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9318037",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 4\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#ref_idxs = Y.var(dim = 0).sort(descending = True)[1][:latent_size] # Find anchor items.\n",
    "ref_idxs = [1,3,6,8]\n",
    "A = torch.ones(latent_size * n_items)\n",
    "b = torch.zeros(latent_size * n_items)\n",
    "for factor_idx in range(latent_size):\n",
    "    ref_idx = ref_idxs[factor_idx]\n",
    "    A[n_items * factor_idx + ref_idx] = 0\n",
    "    b[n_items * factor_idx + ref_idx] = 1 # Fix anchor item's loading on one factor to one.\n",
    "A = A.diag()\n",
    "ints_mask = torch.zeros(n_items)\n",
    "\n",
    "model_name = 'iwave_female'\n",
    "inf_net = [15,8]\n",
    "\n",
    "# model\n",
    "iwave = IWAVE(model_type = \"normal\",\n",
    "              learning_rate = 5e-4 if device==\"cpu\" else 1e-3,\n",
    "              gradient_estimator='dreg',\n",
    "              n_intervals = 100,\n",
    "              device = device,\n",
    "              A = A,\n",
    "              b = b,\n",
    "              ints_mask = ints_mask,\n",
    "              inference_net_sizes = inf_net,\n",
    "              latent_size = latent_size,\n",
    "              n_items = n_items,\n",
    "              fixed_variances = False,\n",
    "              fixed_means = False,\n",
    "              use_spline_prior = False,\n",
    "              log_interval = 25,\n",
    "              )\n",
    "\n",
    "iwave.load_model(model_name, \"./saved_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6ac7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nIWAVE\n",
    "model_name = 'niwave_u13'\n",
    "load_model = os.path.exists(save_dir + '/' + model_name + '.pth')\n",
    "\n",
    "# specs\n",
    "latent_size = 4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ref_idxs = [1,3,6,8]\n",
    "A = torch.ones(latent_size * n_items)\n",
    "b = torch.zeros(latent_size * n_items)\n",
    "for factor_idx in range(latent_size):\n",
    "    ref_idx = ref_idxs[factor_idx]\n",
    "    A[n_items * factor_idx + ref_idx] = 0\n",
    "    b[n_items * factor_idx + ref_idx] = 1 # Fix anchor item's loading on one factor to one.\n",
    "A = A.diag()\n",
    "ints_mask = torch.zeros(n_items)\n",
    "inf_net = [15,8]\n",
    "\n",
    "#### Load second model\n",
    "model_name = 'niwave_female'\n",
    "inf_net = [15,8]\n",
    "\n",
    "niwave = IWAVE(model_type = \"normal\",\n",
    "              learning_rate = 5e-4 if device==\"cpu\" else 1e-3, # Bigger learning rate with increased\n",
    "              gradient_estimator='dreg',\n",
    "              n_intervals = 100,\n",
    "              device = device,\n",
    "              A = A,\n",
    "              b = b,\n",
    "              ints_mask = ints_mask,\n",
    "              inference_net_sizes = inf_net,\n",
    "              latent_size = latent_size,\n",
    "              n_items = n_items,\n",
    "              fixed_variances = False,\n",
    "              fixed_means = False,\n",
    "              use_spline_prior = True,\n",
    "              count_bins = 32,\n",
    "              flow_length = 2,\n",
    "              log_interval = 25,\n",
    "              )\n",
    "\n",
    "niwave.load_model(model_name, \"./saved_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5eee4f",
   "metadata": {},
   "source": [
    "#### Log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f651c7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xt_test = torch.tensor(df_test)\n",
    "#test_size = Xt_test.shape[0]\n",
    "#Y_test = Xt_test.view(test_size, -1)\n",
    "\n",
    "ll = iwave.log_likelihood(data = Y, iw_samples = 5000)\n",
    "nll = niwave.log_likelihood(data = Y, iw_samples = 5000) # Increasing iw_samples\n",
    "print(-ll/sample_size,-nll/sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf9ffd9",
   "metadata": {},
   "source": [
    "#### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d8c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_iwave = iwave.scores(Y, mc_samples=50, iw_samples=50)\n",
    "scores_iwave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fd9b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_niwave = niwave.scores(Y, mc_samples=50, iw_samples=50)\n",
    "scores_niwave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f216a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# why this order of index?\n",
    "final = pd.DataFrame(dat)\n",
    "final['dim1_iwave'] = scores_iwave[:,3]\n",
    "final['dim2_iwave'] = scores_iwave[:,0]\n",
    "final['dim3_iwave'] = scores_iwave[:,2]\n",
    "final['dim4_iwave'] = scores_iwave[:,1]\n",
    "final['dim1_niwave'] = scores_niwave[:,3]\n",
    "final['dim2_niwave'] = scores_niwave[:,0]\n",
    "final['dim3_niwave'] = scores_niwave[:,1]\n",
    "final['dim4_niwave'] = scores_niwave[:,2]\n",
    "final['y'] = y\n",
    "\n",
    "scaled_names = ['relative age scaled',\n",
    "                'height scaled',\n",
    "                'weight scaled',\n",
    "                'sprint (20m) scaled',\n",
    "                'agility scaled',\n",
    "                'dribbling scaled',\n",
    "                'ball control scaled',\n",
    "                'juggling scaled',\n",
    "                'tactical skills scaled',\n",
    "                'kicking skills scaled',\n",
    "                'endurance scaled',\n",
    "                'psychological skills scaled']\n",
    "\n",
    "final = pd.concat([final,pd.DataFrame(df, columns=scaled_names)],axis=1)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5991fb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(save_dir+'/data_scores', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672f5a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "succ = final[final['y']==1]\n",
    "fail = final[final['y']==0]\n",
    "succ_scores = succ.iloc[:,11:15]\n",
    "fail_scores = fail.iloc[:,11:15]\n",
    "\n",
    "succ_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5d1cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "test_result = np.transpose(succ.iloc[:, 1:2].describe().iloc[[1,2], :])\n",
    "temp_0 = np.transpose(fail.iloc[:, 1:2].describe().iloc[[1,2], :])\n",
    "stat, p = ttest_ind(succ.iloc[:, 1],fail.iloc[:, 1])\n",
    "test_result[['mean_0', 'std_0']] = temp_0\n",
    "test_result[\"t-statistic\"] = stat\n",
    "test_result[\"p-value\"] = p\n",
    "for i in range(2, final.iloc[:, 1::].shape[1]):\n",
    "    stat, p = ttest_ind(succ[final.columns[i]],fail[final.columns[i]])\n",
    "    temp = np.transpose(succ.iloc[:, i:(i+1)].describe().iloc[[1,2], :])\n",
    "    temp_0 = np.transpose(fail.iloc[:, i:(i+1)].describe().iloc[[1,2], :])\n",
    "    temp[['mean_0', 'std_0']] = temp_0\n",
    "    temp[\"t-statistic\"] = stat\n",
    "    temp[\"p-value\"] = p\n",
    "    test_result = pd.concat([test_result,temp],axis=0)\n",
    "    # test_result = test_result.append(temp)\n",
    "    # print('For ', name, 'the test statistic is %.3f and p=%.3f' % (stat, p))\n",
    "test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf76dda3",
   "metadata": {},
   "source": [
    "### PCA Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f95ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "#pca_scree = PCA(n_components = 0.75, svd_solver='full')\n",
    "pca_scree = PCA(svd_solver='full')\n",
    "pca_scree.fit(df)\n",
    "reduced = pca_scree.transform(df)\n",
    "pca_scree.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd8fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.plot(pca_scree.explained_variance_ratio_, marker='o')\n",
    "plt.xlabel(\"Eigenvalue number\")\n",
    "plt.ylabel(\"Eigenvalue size\")\n",
    "plt.title(\"Scree Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24be86b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 4, svd_solver='full',)\n",
    "pca.fit(df)\n",
    "reduced = pca.transform(df)\n",
    "loadings = pd.DataFrame(pca.components_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b77566",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(25,12))\n",
    "sns.heatmap(ax=axs[0], data=loadings, annot=True, linewidths=0.5, vmin=loadings.min().min(), vmax=loadings.max().max(), center=0,xticklabels=[\"Factor 1\", \"Factor 2\",\"Factor 3\",\"Factor 4\"], yticklabels=X_names).set(title='PCA loadings')\n",
    "sns.heatmap(ax=axs[1], data=rot_loadings_iwave[:,[3,0,2,1]], annot=True, linewidths=0.5, vmin=rot_loadings_iwave.min(), vmax=rot_loadings_iwave.max(), center=0, xticklabels=[\"Factor 1\", \"Factor 2\",\"Factor 3\",\"Factor 4\"], yticklabels=X_names).set(title='Loadings oblique')\n",
    "sns.heatmap(ax=axs[2], data=rot_loadings_niwave[:,[3,0,1,2,]], annot=True, linewidths=0.5, vmin=rot_loadings_niwave.min(), vmax=rot_loadings_niwave.max(), center=0, xticklabels=[\"Factor 1\", \"Factor 2\",\"Factor 3\",\"Factor 4\"], yticklabels=X_names).set(title='Loadings oblique_spl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a213f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(16,7), frameon=True)\n",
    "sns.heatmap(ax=axs[0], data=abs(loadings), annot=False, linewidths=0.5, linecolor='black', vmin=0, center=loadings.max().max()/2, vmax=loadings.max().max(),xticklabels=[\"Factor 1\", \"Factor 2\",\"Factor 3\",\"Factor 4\"], yticklabels=X_names, cmap = plt.cm.Greys, cbar=True, cbar_kws={'format': matplotlib.ticker.FixedFormatter(['0','max']),\"ticks\":[0,loadings.max().max()],}).set(title='PCA')\n",
    "sns.heatmap(ax=axs[1], data=abs(rot_loadings_iwave[:,[3,0,2,1]]), annot=False, linewidths=0.5, linecolor='black', vmin=0, center=rot_loadings_iwave.max()/2, vmax=rot_loadings_iwave.max(), xticklabels=[\"Factor 1\", \"Factor 2\",\"Factor 3\",\"Factor 4\"], yticklabels=False, cmap = plt.cm.Greys, cbar=True, cbar_kws={'format': matplotlib.ticker.FixedFormatter(['0','max']),\"ticks\":[0,rot_loadings_iwave.max()],}).set(title='Linear loadings')\n",
    "sns.heatmap(ax=axs[2], data=abs(rot_loadings_niwave[:,[3,0,1,2,]]), annot=False, linewidths=0.5, linecolor='black', vmin=0, center=(rot_loadings_niwave.max()-0.7)/2,vmax=rot_loadings_niwave.max()-0.7, xticklabels=[\"Factor 1\", \"Factor 2\",\"Factor 3\",\"Factor 4\"], yticklabels=False, cmap = plt.cm.Greys, cbar_kws={'format': matplotlib.ticker.FixedFormatter(['0','max']),\"ticks\":[0,rot_loadings_niwave.max()-0.7],}).set(title='Nonlinear loadings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0704309",
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_load_table = torch.clone(rot_loadings_iwave)\n",
    "rot_load_table_spl = torch.clone(rot_loadings_niwave)\n",
    "\n",
    "loadings_table = loadings.copy()\n",
    "loadings_table['variable'] = X_names\n",
    "loadings_table.set_index('variable', inplace=True)\n",
    "loadings_table.columns = ['fact. 1', 'fact. 2', 'fact. 3', 'fact. 4']\n",
    "\n",
    "loadings_table[['iwave fact. 1', 'iwave fact. 2', 'iwave fact. 3', 'iwave fact. 4']] = rot_loadings_iwave[:,[3,0,2,1]]\n",
    "loadings_table[['niwave fact. 1', 'niwave fact. 2', 'niwave fact. 3', 'niwave fact. 4']] = rot_loadings_niwave[:,[3,0,1,2,]]\n",
    "\n",
    "loadings_table = round(loadings_table,2)\n",
    "cut_percent = 0.1\n",
    "pca_cut = cut_percent*loadings.max().max()\n",
    "iwave_cut = np.asarray(cut_percent*rot_loadings_iwave.max())\n",
    "niwave_cut = np.asarray(cut_percent*(rot_loadings_niwave.max()-0.7))\n",
    "# pca\n",
    "loadings_table.loc[np.abs(loadings_table['fact. 1']) < pca_cut, 'fact. 1'] = '.'\n",
    "loadings_table.loc[np.abs(loadings_table['fact. 2']) < pca_cut, 'fact. 2'] = '.'\n",
    "loadings_table.loc[np.abs(loadings_table['fact. 3']) < pca_cut, 'fact. 3'] = '.'\n",
    "loadings_table.loc[np.abs(loadings_table['fact. 4']) < pca_cut, 'fact. 4'] = '.'\n",
    "# iwave\n",
    "loadings_table.loc[np.abs(loadings_table['iwave fact. 1']) < iwave_cut, 'iwave fact. 1'] = '.'\n",
    "loadings_table.loc[np.abs(loadings_table['iwave fact. 2']) < iwave_cut, 'iwave fact. 2'] = '.'\n",
    "loadings_table.loc[np.abs(loadings_table['iwave fact. 3']) < iwave_cut, 'iwave fact. 3'] = '.'\n",
    "loadings_table.loc[np.abs(loadings_table['iwave fact. 4']) < iwave_cut, 'iwave fact. 4'] = '.'\n",
    "# niwave\n",
    "loadings_table.loc[np.abs(loadings_table['niwave fact. 1']) < niwave_cut, 'niwave fact. 1'] = '.'\n",
    "loadings_table.loc[np.abs(loadings_table['niwave fact. 2']) < niwave_cut, 'niwave fact. 2'] = '.'\n",
    "loadings_table.loc[np.abs(loadings_table['niwave fact. 3']) < niwave_cut, 'niwave fact. 3'] = '.'\n",
    "loadings_table.loc[np.abs(loadings_table['niwave fact. 4']) < niwave_cut, 'niwave fact. 4'] = '.'\n",
    "\n",
    "\n",
    "print(round(loadings_table,2).to_latex(escape=True, index=True, index_names=False, column_format='lrrrrrrrrrrrr', ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
